I was recently looking at the presentation "ZOMG WHY IS THIS CODE SO SLOW":http://www.slideshare.net/tenderlove/zomg-why-is-this-code-so-slow given by Aaron Patterson (aka "tenderlove":http://tenderlovemaking.com/) at RubyConf 2010. His talk was about benchmarking, performance and optimization in ruby, examples being extracted from his recent work on "ActiveRecord":http://ar.rubyonrails.org/ and "ARel":https://github.com/rails/arel. I must confess being a bit embarrassed about what I'm going to say here (Aaron is a really famous ruby hacker, member of both ruby-core and rails-core teams, developer of excellent ruby tools like "ARel":https://github.com/rails/arel, "mechanize":https://github.com/tenderlove/mechanize, and so on.) but...  I'm a bit... how to say?... hum, surpised! 

The reason is that some examples in the slides can be very misleading IMHO. Amazingly, Aaron himself writes "Don't believe me" and "Think critically". Let's do that: I dare this writing.

h3. Benchmarking and asserting execution time

The example below is given at slide 104, when Aaron introduces the "minitest/benchmark":https://github.com/seattlerb/minitest library (I must add that, at the time of writing, a very similar example is given in "minitest's own README":https://github.com/seattlerb/minitest/blob/81fe0a56f5dd29036e3bec107cca48a136c42470/README.txt#L110-119). 

#<{benchmarking/fib1_test.rb}

The example is quite easy to understand:

# The method @fib@ computes the n-th "fibonacci number":http://en.wikipedia.org/wiki/Fibonacci_number,
# As its name suggests, the method @bench_fib@ aims at benchmarking and asserting the performance of (the implementation of) @fib@. 
# It relies on @assert_performance_linear@ (provided by minitest/benchmark) which will invoke the block with increasing values for @n@ (1, 10, 100, 1000, and 10000). 
# By measuring the execution time of each of these invocations, minitest is able to check whether the execution time is a linear function of @n@ or not.

As you can see below, the test passes. The execution time exhibits a beautiful linear progression! Can we say therefore that @fib@ is a linear function? Not at all!

#<{benchmarking/fib1_result.sh}

h3. Trivially true or simply wrong?

Not at all, because the assertion is trivially true. Therefore the test is useless, if not simply wrong.

#<{ruby}{
assert_performance_linear 0.99 do |n|
  n.times do
    fib(1000)
  end
end
}

Here is why:

# The call to @fib(1000)@ itself has a *constant* execution time _T_ (but see later)
# One call to @fib(1000)@ takes _T_ ms., ten calls take _10*T_ ms., ..., ten thousands calls take _10000*T_ ms.
# The linear progression is implied by @assert_performance_linear@ only, and absolutely independent of @fib@

In other words, the code given in the example is somewhat equivalent to (and the test passes, of course):

#<{ruby}{
assert_performance_linear 0.99 do |n|
  n.times do
    # everything with constant execution time
    # nothing, for example
  end
end
}

The assertion is trivially true as well as the test, and the benchmarking approach itself is misleading, if not wrong.

h3. Really?

Unfortunately if you want to go deeper in your understanding, things get more complicated. The truth is that answering whether the benchmarking is wrong or not depends on what you want to assert precisely. In this respect, the example at hand is amazing because:

!!{it proves (or at least asserts) a lot of things, but *certainly not* that @fib@ has a linear execution time (even if it does)}

If you do not trust me, modify @fib@ as below. The modified implementation (does not compute a fibonacci number anymore and) has certainly an exponential execution time in _n_.

#<{ruby}{
def fib n
  a, b = 0, 1
  (2**n).times do 
    a, b = b, a + b 
  end
  a
end
}

Execute the test now (I've only replaced 1000 by 10 here to have something that ends in a reasonable amount of time. Sorry for the confusion it could introduce):

#<{ruby}{
assert_performance_linear 0.99 do |n|
  n.times do
    fib(10) 
  end
end
}

#<{benchmarking/fib2_result.sh}

The test passes and the performance is linear (the execution time is even really similar than what we had before, but it simply because @10**2 == 1024 ~= 1000@). But the same will be true whatever the @fib@ you choose, and whatever it's internal complexity: constant, linear, polynomial, or even exponential! Contrarily to what is argued by Aaron, this kind of test will never detect the fact that your mate have replaced your linear function by an exponential one.

So what is asserted exactly? Is the assertion trivially true, really? No exactly. In fact, the test tests that:

# The method @Integer#times(n)@ has a linear execution time with respect to @n@ and
# The call to @fib(1000)@ has a constant execution time, which implies that...
# ... it does not (seem to) depend on the number of times the function has been called before and
# ... it does not (seem to) depend on another hidden parameter unless the latter is itself constant and
# ... so on.


h3. What happened?

At this step, you could argue that it is a typo on the slide and that the bench method was intended to be as shown below:

#<{ruby}{
assert_performance_linear 0.99 do |n|
  n.times do
    fib(n) 
  end
end
}

But no way! The test even fails, and *has to fail*: @Integer#times@ is linear in @n@ and calls @fib@ at each iteration, which is linear in @n@ as well. The correct computation is therefore @n*n@, which is quadratic, not linear. Moreover, a similar mistake would be repeated on many other slides (see slides 100-102, 104-106, 109-114, 165-166, ...). 

What about the example below?

#<{ruby}{
assert_performance_linear 0.99 do |n|
  n.times do |i|
    fib(i) 
  end
end
}

Well, this time, the exact complexity formula is @n * (n + 1)/2@, which is bounded by @n^2@ and therefore quadratic, not linear. Contrast this with

#<{ruby}{
assert_performance_linear 0.99 do |n|
  100.times do
    fib(n) 
  end
end
}

Or simply:

#<{ruby}{
assert_performance_linear 0.99 do |n|
  fib(n) 
end
}

The last two examples are right, and correctly assert that @fib@ itself has a linear complexity. The first one repeats the computation 100 times, which allows having better statistical results. 

What happened? Probably a simple mix of concerns: having correct measures, i.e. @fib(n)@, with relevant statistical results (i.e., @n.times do ... end@). This mix of concerns has probably led to a mix of variables (there's two different @n@, in fact),... 

h3. Conclusion

!!{The same as Aaron, I'm affraid: we should not forget the Science ;-)}
